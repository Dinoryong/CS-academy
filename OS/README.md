# Operating Systems

-------

<br>

CPU Scheduling

DeadLock

File System

IPC

Interrupt

Memory

Operating System

PCB & Context Switching

Page Replacement Algorithm

Paging and Segmentation

Process Address Space

Process Management & PCB

Process vs Thread

Race Condition

Semaphore & Mutex

System Call(fork Wait Exec)

<br>

# CPU Scheduling

### **1. 스케줄링**

> CPU 를 잘 사용하기 위해 프로세스를 잘 배정하기

- 조건 : 오버헤드 ↓ / 사용률 ↑ / 기아 현상 ↓
- 목표
  1. `Batch System`: 가능하면 많은 일을 수행. 시간(time) 보단 처리량(throughout)이 중요
  2. `Interactive System`: 빠른 응답 시간. 적은 대기 시간.
  3. `Real-time System`: 기한(deadline) 맞추기.

<br>

### **2. 선점 / 비선점 스케줄링**

- 선점 (preemptive) : OS가 CPU의 사용권을 선점할 수 있는 경우, 강제 회수하는 경우
- 비선점 (nonpreemptive) : 프로세스 종료 or I/O 등의 이벤트가 있을 때까지 실행 보장 (처리시간 예측 어려움)

<br>

### **3. 프로세스 상태**

![https://user-images.githubusercontent.com/13609011/91695344-f2dfae80-eba8-11ea-9a9b-702192316170.jpeg](https://user-images.githubusercontent.com/13609011/91695344-f2dfae80-eba8-11ea-9a9b-702192316170.jpeg)

- 비선점 스케줄링 : `Interrupt`, `Scheduler Dispatch`
- 선점 스케줄링 : `I/O or Event Wait`

------

**프로세스의 상태 전이**

✓ **승인 (Admitted)** : 프로세스 생성이 가능하여 승인됨.

✓ **스케줄러 디스패치 (Scheduler Dispatch)** : 준비 상태에 있는 프로세스 중 하나를 선택하여 실행시키는 것.

✓ **인터럽트 (Interrupt)** : 예외, 입출력, 이벤트 등이 발생하여 현재 실행 중인 프로세스를 준비 상태로 바꾸고, 해당 작업을 먼저 처리하는 것.

✓ **입출력 또는 이벤트 대기 (I/O or Event wait)** : 실행 중인 프로세스가 입출력이나 이벤트를 처리해야 하는 경우, 입출력/이벤트가 모두 끝날 때까지 대기 상태로 만드는 것.

✓ **입출력 또는 이벤트 완료 (I/O or Event Completion)** : 입출력/이벤트가 끝난 프로세스를 준비 상태로 전환하여 스케줄러에 의해 선택될 수 있도록 만드는 것.

<br>

### **4. CPU 스케줄링의 종류**

- 비선점 스케줄링 (Non-Preemptive Scheduling)

  1. FCFS (First Come First Served)
     - 큐에 도착한 순서대로 CPU 할당
     - 실행 시간이 짧은 게 뒤로 가면 평균 대기 시간이 길어짐
     - 일단 CPU 를 잡으면 CPU burst 가 완료될 때까지 CPU 를 반환하지 않는다. 할당되었던 CPU 가 반환될 때만 스케줄링이 이루어진다. ( aka 비선점형 Non-Preemptive 스케줄링 )
     - 문제점 : convoy effect - 소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상이 발생한다.
  2. SJF (Shortest Job First)
     - 수행시간이 가장 짧다고 판단되는 작업을 먼저 수행
     - 다른 프로세스가 먼저 도착했어도 CPU burst time 이 짧은 프로세스에게 선 할당
     - FCFS 보다 평균 대기 시간 감소, 짧은 작업에 유리
     - 문제점 : starvation - 효율성을 추구하는게 가장 중요하지만 특정 프로세스가 지나치게 차별받으면 안되는 것이다. 이 스케줄링은 극단적으로 CPU 사용이 짧은 job 을 선호한다. 그래서 사용 시간이 긴 프로세스는 거의 영원히 CPU 를 할당받을 수 없다.

- 선점 스케줄링

  1. Priority Scheduling

     - 정적/동적으로 우선순위를 부여하여 우선순위가 높은 순서대로 처리
     - 우선순위가 가장 높은 프로세스에게 CPU 를 할당하는 스케줄링이다. 우선순위란 정수로 표현하게 되고 작은 숫자가 우선순위가 높다.
     - 더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU 를 선점한다. → aka 선점형 스케줄링(Preemptive) 방식
     - 더 높은 우선순위의 프로세스가 도착하면 Ready Queue 의 Head 에 넣는다. → aka 비선점형 스케줄링(Non-Preemptive) 방식
     - 문제점 : Starvation - 우선 순위가 낮은 프로세스가 무한정 기다리는 Starvation 이 생길 수 있음, 무기한 봉쇄(Indefinite blocking) - 실행 준비는 되어있으나 CPU 를 사용못하는 프로세스를 CPU 가 무기한 대기하는 상태
     - 해결책 : Aging 방법으로 Starvation 문제 해결 가능 - 아무리 우선순위가 낮은 프로세스라도 오래 기다리면 우선순위를 높여주자.

  2. Round Robin

     - 현대적인 CPU 스케줄링

     - 각 프로세스는 동일한 크기의 할당 시간(time quantum)을 갖게 된다.

     - 할당 시간이 지나면 프로세스는 선점당하고 ready queue 의 제일 뒤에 가서 다시 줄을 선다.

     - `RR`은 CPU 사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적

     - `RR`이 가능한 이유는 프로세스의 context 를 save 할 수 있기 때문이다.

     - FCFS에 의해 프로세스들이 보내지면 각 프로세스는 동일한 시간의 

       ```
       Time Quantum
       ```

        만큼 CPU를 할달 받음

       - `Time Quantum` or `Time Slice` : 실행의 최소 단위 시간

     - 할당 시간(`Time Quantum`)이 크면 FCFS와 같게 되고, 작으면 문맥 교환 (Context Switching) 잦아져서 오버헤드 증가

     - 장점 1 : Response time이 빨라진다. - n 개의 프로세스가 ready queue 에 있고 할당시간이 q(time quantum)인 경우 각 프로세스는 q 단위로 CPU 시간의 1/n 을 얻는다. 즉, 어떤 프로세스도 (n-1)q time unit 이상 기다리지 않는다.

     - 장점 2 : 프로세스가 기다리는 시간이 CPU 를 사용할 만큼 증가한다.공정한 스케줄링이라고 할 수 있다.

     - 주의점 : 설정한 time quantum이 너무 커지면 FCFS와 같아진다. 또 너무 작아지면 스케줄링 알고리즘의 목적에는 이상적이지만 잦은 context switch 로 overhead 가 발생한다. 그렇기 때문에 적당한 time quantum을 설정하는 것이 중요하다.

  3. Multilevel-Queue (다단계 큐)

     ![https://user-images.githubusercontent.com/13609011/91695428-16a2f480-eba9-11ea-8d91-17d22bab01e5.png](https://user-images.githubusercontent.com/13609011/91695428-16a2f480-eba9-11ea-8d91-17d22bab01e5.png)

     - 작업들을 여러 종류의 그룹으로 나누어 여러 개의 큐를 이용하는 기법

       ![https://user-images.githubusercontent.com/13609011/91695480-2a4e5b00-eba9-11ea-8dbf-390bf0a73c10.png](https://user-images.githubusercontent.com/13609011/91695480-2a4e5b00-eba9-11ea-8dbf-390bf0a73c10.png)

     - 우선순위가 낮은 큐들이 실행 못하는 걸 방지하고자 각 큐마다 다른 `Time Quantum`을 설정 해주는 방식 사용

     - 우선순위가 높은 큐는 작은 `Time Quantum` 할당. 우선순위가 낮은 큐는 큰 `Time Quantum` 할당.

  4. Multilevel-Feedback-Queue (다단계 피드백 큐)

  ![https://user-images.githubusercontent.com/13609011/91695489-2cb0b500-eba9-11ea-8578-6602fee742ed.png](https://user-images.githubusercontent.com/13609011/91695489-2cb0b500-eba9-11ea-8578-6602fee742ed.png)

  - 다단계 큐에서 자신의 

    ```
    Time Quantum
    ```

    을 다 채운 프로세스는 밑으로 내려가고 자신의 

    ```
    Time Quantum
    ```

    을 다 채우지 못한 프로세스는 원래 큐 그대로

    - Time Quantum을 다 채운 프로세스는 CPU burst 프로세스로 판단하기 때문

  - 짧은 작업에 유리, 입출력 위주(Interrupt가 잦은) 작업에 우선권을 줌

  - 처리 시간이 짧은 프로세스를 먼저 처리하기 때문에 Turnaround 평균 시간을 줄여줌

  1. SRT (Shortest Remaining time First)

  - 새로운 프로세스가 도착할 때마다 새로운 스케줄링이 이루어진다.
  - 현재 수행중인 프로세스의 남은 burst time 보다 더 짧은 CPU burst time 을 가지는 새로운 프로세스가 도착하면 CPU 를 뺏긴다. → aka 선점형 스케줄링
  - 문제점 : starvation - 새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문에 CPU burst time(CPU 사용시간)을 측정할 수가 없다.

<br>

### **5. CPU 스케줄링 척도**

1. Response Time
   - 작업이 처음 실행되기까지 걸린 시간
2. Turnaround Time
   - 실행 시간과 대기 시간을 모두 합한 시간으로 작업이 완료될 때 까지 걸린 시간

<br>

# DeadLock

### ***데드락(DeadLock)\***

> 프로세스가 자원을 얻지 못해서 다음 처리를 하지 못하는 상태'교착 상태'라고도 부름시스템적으로 한정된 자원을 여러 곳에서 사용하려고 할 때 발생

- 데드락이 일어나는 경우

https://camo.githubusercontent.com/a78df4477534741d6058a959e753fe82050589944c8801b4fc88c23d4696fcad/68747470733a2f2f74312e6461756d63646e2e6e65742f6366696c652f746973746f72792f323433453839333535373134433236453238

프로세스1과 2가 자원1,2를 모두 얻어야 한다고 가정해보자

t1 : 프로세스1이 자원1을 얻음 / 프로세스2가 자원2를 얻음

t2 : 프로세스1은 자원2를 기다림 / 프로세스2는 자원1을 기다림

현재 서로 원하는 자원이 상대방에 할당되어 있어서 두 프로세스는 무한정 wait 상태에 빠짐

→ 이것이 바로 **DeadLock**!!!!!!

(주로 발생하는 경우)

> 멀티 프로그래밍 환경에서 한정된 자원을 얻기 위해 서로 경쟁하는 상황 발생한 프로세스가 자원을 요청했을 때, 동시에 그 자원을 사용할 수 없는 상황이 발생할 수 있음. 이때 프로세스는 대기 상태로 들어감대기 상태로 들어간 프로세스들이 실행 상태로 변경될 수 없을 때 '교착 상태' 발생

### ***데드락(DeadLock) 발생 조건\***

> 4가지 모두 성립해야 데드락 발생(하나라도 성립하지 않으면 데드락 문제 해결 가능)

1. **상호 배제(Mutual exclusion)**

   > 자원은 한번에 한 프로세스만 사용할 수 있음

2. **점유 대기(Hold and wait)**

   > 최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 존재해야 함

3. **비선점(No preemption)**

   > 다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없음

4. **순환 대기(Circular wait)**

   > 프로세스의 집합에서 순환 형태로 자원을 대기하고 있어야 함

### ***데드락(DeadLock) 처리\***

------

### **교착 상태를 예방 & 회피**

1. **예방(prevention)**

   교착 상태 발생 조건 중 하나를 제거하면서 해결한다 (자원 낭비 엄청 심함)

   > 상호배제 부정 : 여러 프로세스가 공유 자원 사용점유대기 부정 : 프로세스 실행전 모든 자원을 할당비선점 부정 : 자원 점유 중인 프로세스가 다른 자원을 요구할 때 가진 자원 반납순환대기 부정 : 자원에 고유번호 할당 후 순서대로 자원 요구

2. **회피(avoidance)**

   교착 상태 발생 시 피해나가는 방법

   > 은행원 알고리즘(Banker's Algorithm)은행에서 모든 고객의 요구가 충족되도록 현금을 할당하는데서 유래함프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있게 되는지 사전에 검사하여 교착 상태 회피안정 상태면 자원 할당, 아니면 다른 프로세스들이 자원 해지까지 대기

### **교착 상태를 탐지 & 회복**

교착 상태가 되도록 허용한 다음 회복시키는 방법

1. **탐지(Detection)**

   자원 할당 그래프를 통해 교착 상태를 탐지함

   자원 요청 시, 탐지 알고리즘을 실행시켜 그에 대한 오버헤드 발생함

2. **회복(Recovery)**

   교착 상태 일으킨 프로세스를 종료하거나, 할당된 자원을 해제시켜 회복시키는 방법

   > 프로세스 종료 방법교착 상태의 프로세스를 모두 중지교착 상태가 제거될 때까지 하나씩 프로세스 중지자원 선점 방법교착 상태의 프로세스가 점유하고 있는 자원을 선점해 다른 프로세스에게 할당 (해당 프로세스 일시정지 시킴)우선 순위가 낮은 프로세스나 수행 횟수 적은 프로세스 위주로 프로세스 자원 선점

### **주요 질문**

1. 데드락(교착 상태)가 뭔가요? 발생 조건에 대해 말해보세요.

2. 회피 기법인 은행원 알고리즘이 뭔지 설명해보세요.

3. 기아상태를 설명하는 식사하는 철학자 문제에 대해 설명해보세요.

   > 교착 상태 해결책n명이 앉을 수 있는 테이블에서 철학자를 n-1명만 앉힘한 철학자가 젓가락 두개를 모두 집을 수 있는 상황에서만 젓가락 집도록 허용누군가는 왼쪽 젓가락을 먼저 집지 않고 오른쪽 젓가락을 먼저 집도록 허용

<br>

저장매체에는 수많은 파일이 있기 때문에, 이런 파일들을 관리하는 방법을 말한다.

### 

### **특징**

- 커널 영역에서 동작
- 파일 CRUD 기능을 원활히 수행하기 위한 목적
- 계층적 디렉터리 구조를 가짐
- 디스크 파티션 별로 하나씩 둘 수 있음

### **역할**

- 파일 관리
- 보조 저장소 관리
- 파일 무결성 메커니즘
- 접근 방법 제공

### **개발 목적**

- 하드디스크와 메인 메모리 속도차를 줄이기 위함
- 파일 관리
- 하드디스크 용량 효율적 이용

### **구조**

- 메타 영역 : 데이터 영역에 기록된 파일의 이름, 위치, 크기, 시간정보, 삭제유무 등의 파일 정보
- 데이터 영역 : 파일의 데이터

### **접근 방법**

1. **순차 접근(Sequential Access)**

   > 가장 간단한 접근 방법으로, 대부분 연산은 read와 write

   https://camo.githubusercontent.com/3d98ce630359f31bcff0c3741e2a230ef161c4d6239803e722ca054a7a981751/68747470733a2f2f6e6f65702e6769746875622e696f2f323031362f30322f32332f313074682d66696c6573797374656d2f31302e312e706e67

   현재 위치를 가리키는 포인터에서 시스템 콜이 발생할 경우 포인터를 앞으로 보내면서 read와 write를 진행. 뒤로 돌아갈 땐 지정한 offset만큼 되감기를 해야 한다. (테이프 모델 기반)

2. **직접 접근(Direct Access)**

   > 특별한 순서없이, 빠르게 레코드를 read, write 가능

   https://camo.githubusercontent.com/7561e732c8eec57fe126bce5f3d2f8e5dfd8cd7d2210eb275d249699db15f0d6/68747470733a2f2f6e6f65702e6769746875622e696f2f323031362f30322f32332f313074682d66696c6573797374656d2f31302e322e706e67

   현재 위치를 가리키는 cp 변수만 유지하면 직접 접근 파일을 가지고 순차 파일 기능을 쉽게 구현이 가능하다.

   무작위 파일 블록에 대한 임의 접근을 허용한다. 따라서 순서의 제약이 없음

   대규모 정보를 접근할 때 유용하기 때문에 '데이터베이스'에 활용된다.

3. 기타 접근

   > 직접 접근 파일에 기반하여 색인 구축

   https://camo.githubusercontent.com/47fc4842a54b5e76f61a6a6dd6e3403a223f3d51c22ad2dad9f08a68e3cfd2ac/68747470733a2f2f6e6f65702e6769746875622e696f2f323031362f30322f32332f313074682d66696c6573797374656d2f31302e332e706e67

   크기가 큰 파일을 입출력 탐색할 수 있게 도와주는 방법임

### **디렉터리와 디스크 구조**

------

- **1단계 디렉터리**

  > 가장 간단한 구조

  파일들은 서로 유일한 이름을 가짐. 서로 다른 사용자라도 같은 이름 사용 불가

  https://camo.githubusercontent.com/64e17df3257a6613a4dd3785c29992e5a11b5d3ad2921335bf79c3a7c69f959e/68747470733a2f2f6e6f65702e6769746875622e696f2f323031362f30322f32332f313074682d66696c6573797374656d2f31302e352e706e67

- **2단계 디렉터리**

  > 사용자에게 개별적인 디렉터리 만들어줌

  - UFD : 자신만의 사용자 파일 디렉터리
  - MFD : 사용자의 이름과 계정번호로 색인되어 있는 디렉터리

  https://camo.githubusercontent.com/481d06b7e5e499c43e916ea8412a130be2f6bbb5cad332d6f6d3e327a0acf0d1/68747470733a2f2f6e6f65702e6769746875622e696f2f323031362f30322f32332f313074682d66696c6573797374656d2f31302e362e706e67

- **트리 구조 디렉터리**

  > 2단계 구조 확장된 다단계 트리 구조

  한 비트를 활용하여, 일반 파일(0)인지 디렉터리 파일(1) 구분

  https://camo.githubusercontent.com/84f459c97d762e85f623e5198699e8e2f6353eb4b97489390fac3f21bc012555/68747470733a2f2f6e6f65702e6769746875622e696f2f323031362f30322f32332f313074682d66696c6573797374656d2f31302e372e706e67

- 그래프 구조 디렉터리

  > 순환이 발생하지 않도록 하위 디렉터리가 아닌 파일에 대한 링크만 허용하거나, 가비지 컬렉션을 이용해 전체 파일 시스템을 순회하고 접근 가능한 모든 것을 표시

  링크가 있으면 우회하여 순환을 피할 수 있음

  https://camo.githubusercontent.com/1bcf4d313ab3dd04f9c747a86e12943c1fe978758f85f6a8069cb018ff4f5198/68747470733a2f2f6e6f65702e6769746875622e696f2f323031362f30322f32332f313074682d66696c6573797374656d2f31302e392e706e67



# IPC

### **IPC(Inter Process Communication)**

------

https://camo.githubusercontent.com/ae371b6a70f7e11ebfbbd4cda052d103e6cf8c7e39b8ae3fd81e5396ef9bb9a8/68747470733a2f2f74312e6461756d63646e2e6e65742f6366696c652f746973746f72792f393944423843343935433443353730343137

프로세스는 독립적으로 실행된다. 즉, 독립 되어있다는 것은 다른 프로세스에게 영향을 받지 않는다고 말할 수 있다. (스레드는 프로세스 안에서 자원을 공유하므로 영향을 받는다)

이런 독립적 구조를 가진 **프로세스 간의 통신**을 해야 하는 상황이 있을 것이다. 이를 가능하도록 해주는 것이 바로 IPC 통신이다.

프로세스는 커널이 제공하는 IPC 설비를 이용해 프로세스간 통신을 할 수 있게 된다.

***커널이란?\***

> 운영체제의 핵심적인 부분으로, 다른 모든 부분에 여러 기본적인 서비스를 제공해줌

IPC 설비 종류도 여러가지가 있다. 필요에 따라 IPC 설비를 선택해서 사용해야 한다.

### **IPC 종류**

1. **익명 PIPE**

   > 파이프는 두 개의 프로세스를 연결하는데 하나의 프로세스는 데이터를 쓰기만 하고, 다른 하나는 데이터를 읽기만 할 수 있다.한쪽 방향으로만 통신이 가능한 반이중 통신이라고도 부른다.따라서 양쪽으로 모두 송/수신을 하고 싶으면 2개의 파이프를 만들어야 한다.매우 간단하게 사용할 수 있는 장점이 있고, 단순한 데이터 흐름을 가질 땐 파이프를 사용하는 것이 효율적이다. 단점으로는 전이중 통신을 위해 2개를 만들어야 할 때는 구현이 복잡해지게 된다.

2. **Named PIPE(FIFO)**

   > 익명 파이프는 통신할 프로세스를 명확히 알 수 있는 경우에 사용한다. (부모-자식 프로세스 간 통신처럼)Named 파이프는 전혀 모르는 상태의 프로세스들 사이 통신에 사용한다.즉, 익명 파이프의 확장된 상태로 부모 프로세스와 무관한 다른 프로세스도 통신이 가능한 것 (통신을 위해 이름있는 파일을 사용)하지만, Named 파이프 역시 읽기/쓰기 동시에 불가능함. 따라서 전이중 통신을 위해서는 익명 파이프처럼 2개를 만들어야 가능

3. **Message Queue**

   > 입출력 방식은 Named 파이프와 동일함다른점은 메시지 큐는 파이프처럼 데이터의 흐름이 아니라 메모리 공간이다.사용할 데이터에 번호를 붙이면서 여러 프로세스가 동시에 데이터를 쉽게 다룰 수 있다.

4. **공유 메모리**

   > 파이프, 메시지 큐가 통신을 이용한 설비라면, 공유 메모리는 데이터 자체를 공유하도록 지원하는 설비다.프로세스의 메모리 영역은 독립적으로 가지며 다른 프로세스가 접근하지 못하도록 반드시 보호되야한다. 하지만 다른 프로세스가 데이터를 사용하도록 해야하는 상황도 필요할 것이다. 파이프를 이용해 통신을 통해 데이터 전달도 가능하지만, 스레드처럼 메모리를 공유하도록 해준다면 더욱 편할 것이다.공유 메모리는 프로세스간 메모리 영역을 공유해서 사용할 수 있도록 허용해준다.프로세스가 공유 메모리 할당을 커널에 요청하면, 커널은 해당 프로세스에 메모리 공간을 할당해주고 이후 모든 프로세스는 해당 메모리 영역에 접근할 수 있게 된다.중개자 없이 곧바로 메모리에 접근할 수 있어서 IPC 중에 가장 빠르게 작동함

5. **메모리 맵**

   > 공유 메모리처럼 메모리를 공유해준다. 메모리 맵은 열린 파일을 메모리에 맵핑시켜서 공유하는 방식이다. (즉 공유 매개체가 파일+메모리)주로 파일로 대용량 데이터를 공유해야 할 때 사용한다.

6. **소켓**

   > 네트워크 소켓 통신을 통해 데이터를 공유한다.클라이언트와 서버가 소켓을 통해서 통신하는 구조로, 원격에서 프로세스 간 데이터를 공유할 때 사용한다.서버(bind, listen, accept), 클라이언트(connect)

이러한 IPC 통신에서 프로세스 간 데이터를 동기화하고 보호하기 위해 세마포어와 뮤텍스를 사용한다. (공유된 자원에 한번에 하나의 프로세스만 접근시킬 때)

<br>

# Interrupt

## **인터럽트(Interrupt)**

### **정의**

프로그램을 실행하는 도중에 예기치 않은 상황이 발생할 경우 현재 실행 중인 작업을 즉시 중단하고, 발생된 상황을 우선 처리한 후 실행 중이던 작업으로 복귀하여 계속 처리하는 것

지금 수행 중인 일보다 더 중요한 일(ex. 입출력, 우선 순위 연산 등)이 발생하면 그 일을 먼저 처리하고 나서 하던 일을 계속해야한다.

외부/내부 인터럽트는 `CPU의 하드웨어 신호에 의해 발생`

소프트웨어 인터럽트는 `명령어의 수행에 의해 발생`

- **외부 인터럽트**

  입출력 장치, 타이밍 장치, 전원 등 외부적인 요인으로 발생

  `전원 이상, 기계 착오, 외부 신호, 입출력`

- **내부 인터럽트**

  Trap이라고 부르며, 잘못된 명령이나 데이터를 사용할 때 발생

  > 0으로 나누기가 발생, 오버플로우, 명령어를 잘못 사용한 경우 (Exception)

- **소프트웨어 인터럽트**

  프로그램 처리 중 명령의 요청에 의해 발생한 것 (SVC 인터럽트)

  > 사용자가 프로그램을 실행시킬 때 발생소프트웨어 이용 중에 다른 프로세스를 실행시키면 시분할 처리를 위해 자원 할당 동작이 수행된다.

### **인터럽트 발생 처리 과정**

주 프로그램이 실행되다가 인터럽트가 발생했다.

현재 수행 중인 프로그램을 멈추고, 상태 레지스터와 PC 등을 스택에 잠시 저장한 뒤에 인터럽트 서비스 루틴으로 간다. (잠시 저장하는 이유는, 인터럽트 서비스 루틴이 끝난 뒤 다시 원래 작업으로 돌아와야 하기 때문)

만약 **인터럽트 기능이 없었다면**, 컨트롤러는 특정한 어떤 일을 할 시기를 알기 위해 계속 체크를 해야 한다. (이를 **폴링(Polling)**이라고 한다)

폴링을 하는 시간에는 원래 하던 일에 집중할 수가 없게 되어 많은 기능을 제대로 수행하지 못하는 단점이 있었다.

즉, 컨트롤러가 입력을 받아들이는 방법(우선순위 판별방법)에는 두가지가 있다.

- **폴링 방식**

  사용자가 명령어를 사용해 입력 핀의 값을 계속 읽어 변화를 알아내는 방식

  인터럽트 요청 플래그를 차례로 비교하여 우선순위가 가장 높은 인터럽트 자원을 찾아 이에 맞는 인터럽트 서비스 루틴을 수행한다. (하드웨어에 비해 속도 느림)

- **인터럽트 방식**

  MCU 자체가 하드웨적으로 변화를 체크하여 변화 시에만 일정한 동작을 하는 방식

  - Daisy Chain
  - 병렬 우선순위 부여

인터럽트 방식은 하드웨어로 지원을 받아야 하는 제약이 있지만, 폴링에 비해 신속하게 대응하는 것이 가능하다. 따라서 **'실시간 대응'**이 필요할 때는 필수적인 기능이다.

즉, 인터럽트는 **발생시기를 예측하기 힘든 경우에 컨트롤러가 가장 빠르게 대응할 수 있는 방법**이다.

<br>

# Memory

### **메인 메모리(main memory)**

> 메인 메모리는 CPU가 직접 접근할 수 있는 접근 장치프로세스가 실행되려면 프로그램이 메모리에 올라와야 함

주소가 할당된 일련의 바이트들로 구성되어 있음

CPU는 레지스터가 지시하는대로 메모리에 접근하여 다음에 수행할 명령어를 가져옴

명령어 수행 시 메모리에 필요한 데이터가 없으면 해당 데이터를 우선 가져와야 함

이 역할을 하는 것이 바로 MMU

메모리 관리장치(MMU)는 논리 주소를 물리주소로 변환해줌

뿐만 아니라 메모리 보호나 캐시 관리 등 CPU가 메모리에 접근하는 것을 총 관리해주는 하드웨어임

메모리의 공간이 한정적이기 때문에, 사용자에게 더 많은 메모리를 제공하기 위해 '가상 주소'라는 개념이 등장 (가상 주소는 프로그램 상에서 사용자가 보는 주소 공간이라고 보면 됨)

이 가상 주소에서 실제 데이터가 담겨 있는 곳에 접근하기 위해선 빠른 주소 변환이 필요한데, 이를 MMU가 도와주는 것

또한 메인 메모리의 직접 접근은 비효율적이므로, CPU와 메인 메모리 속도를 맞추기 위해 캐시가 존재함

### **MMU의 메모리 보호**

프로세스는 독립적인 메모리 공간을 가져야 되고, 자신의 공간만 접근해야 함

따라서 한 프로세스에게 합법적인 주소 영역을 설정하고, 잘못된 접근이 오면 trap을 발생시키며 보호함

https://camo.githubusercontent.com/d1cf6d562e863683d43c4a26178ad484458ac547185ee156734ac88de08a6fda/68747470733a2f2f696d67312e6461756d63646e2e6e65742f7468756d622f523132383078302f3f73636f64653d6d746973746f727926666e616d653d68747470732533412532462532466b2e6b616b616f63646e2e6e6574253246646e253246354c677574253246627471754e764b4d5277482532464a4f717a636d7a3877695866304b76376f6b66477a4b253246696d672e706e67

base와 limit 레지스터를 활용한 메모리 보호 기법

base 레지스터는 메모리상의 프로세스 시작주소를 물리 주소로 저장 limit 레지스터는 프로세스의 사이즈를 저장

이로써 프로세스의 접근 가능한 합법적인 메모리 영역(x)은

```
base <= x < base+limit
```

이 영역 밖에서 접근을 요구하면 trap을 발생시키는 것

안전성을 위해 base와 limit 레지스터는 커널 모드에서만 수정 가능하도록 설계 (사용자 모드에서는 직접 변경할 수 없도록)

### **메모리 과할당(over allocating)**

> 실제 메모리의 사이즈보다 더 큰 사이즈의 메모리를 프로세스에 할당한 상황

페이지 기법과 같은 메모리 관리 기법은 사용자가 눈치 채지 못하도록 눈속임을 통해 메모리를 할당해줌 (가상 메모리를 이용해서)

과할당 상황에 대해서 사용자를 속인 것을 들킬만한 상황이 존재함

1. 프로세스 실행 도중 페이지 폴트 발생
2. 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 찾음
3. 메모리의 빈 프레임에 페이지를 올려야 하는데, 모든 메모리가 사용중이라 빈 프레임이 없음

이러한 과할당을 해결하기 위해선, 빈 프레임을 확보할 수 있어야 함

1. 메모리에 올라와 있는 한 프로세스를 종료시켜 빈 프레임을 얻음
2. 프로세스 하나를 swap out하고, 이 공간을 빈 프레임으로 활용

swapping 기법을 통해 공간을 바꿔치기하는 2번 방법과는 달리 1번은 사용자에게 페이징 시스템을 들킬 가능성이 매우 높아서 하면 안됨

(페이징 기법은 사용자 모르게 시스템 능률을 높이기 위해 선택한 일이므로 들키지 않게 처리해야한다)

따라서, 2번과 같은 해결책을 통해 페이지 교체가 이루어져야 함

### **페이지 교체**

> 메모리 과할당이 발생했을 때, 프로세스 하나를 swap out해서 빈 프레임을 확보하는 것

1. 프로세스 실행 도중 페이지 부재 발생

2. 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 찾음

3. 메모리에 빈 프레임이 있는지 확인

   > 빈 프레임이 있으면 해당 프레임을 사용빈 프레임이 없으면, victim 프레임을 선정해 디스크에 기록하고 페이지 테이블을 업데이트함

4. 빈 프레임에 페이지 폴트가 발생한 페이지를 올리고, 페이지 테이블 업데이트

페이지 교체가 이루어지면 아무일이 없던것 처럼 프로세스를 계속 수행시켜주면서 사용자가 알지 못하도록 해야 함

이때, 아무일도 일어나지 않은 것처럼 하려면, 페이지 교체 당시 오버헤드를 최대한 줄여야 함

### **오버헤드를 감소시키는 해결법**

이처럼 빈 프레임이 없는 상황에서 victim 프레임을 비울 때와 원하는 페이지를 프레임으로 올릴 때 두 번의 디스크 접근이 이루어짐

페이지 교체가 많이 이루어지면, 이처럼 입출력 연산이 많이 발생하게 되면서 오버헤드 문제가 발생함

### **방법1**

변경비트를 모든 페이지마다 둬서, victim 페이지가 정해지면 해당 페이지의 비트를 확인

해당 비트가 set 상태면? → 해당 페이지 내용이 디스크 상의 페이지 내용과 달라졌다는 뜻 (즉, 페이지가 메모리 올라온 이후 한번이라도 수정이 일어났던 것. 따라서 이건 디스크에 기록해야함)

bit가 clear 상태라면? → 디스크 상의 페이지 내용과 메모리 상의 페이지가 정확히 일치하는 상황 (즉, 디스크와 내용이 같아서 기록할 필요가 없음)

비트를 활용해 디스크에 기록하는 횟수를 줄이면서 오버헤드에 대한 수를 최대 절반으로 감소시키는 방법임

### **방법2**

페이지 교체 알고리즘을 상황에 따라 잘 선택해야 함

현재 상황에서 페이지 폴트를 발생할 확률을 최대한 줄여줄 수 있는 교체 알고리즘을 사용

FIFO

OPT

LRU

### **캐시 메모리**

> 주기억장치에 저장된 내용의 일부를 임시로 저장해두는 기억장치CPU와 주기억장치의 속도 차이로 성능 저하를 방지하기 위한 방법

CPU가 이미 봤던걸 다시 재접근할 때, 메모리 참조 및 인출 과정에 대한 비용을 줄이기 위해 캐시에 저장해둔 데이터를 활용한다

캐시는 플리플롭 소자로 구성되어 SRAM으로 되어있어서 DRAM보다 빠른 장점을 지님

### **CPU와 기억장치의 상호작용**

CPU에서 주소를 전달 → 캐시 기억장치에 명령이 존재하는지 확인

(존재) Hit

해당 명령어를 CPU로 전송 → 완료

(비존재) Miss

명령어를 갖고 주기억장치로 접근 → 해당 명령어를 가진 데이터 인출 → 해당 명령어 데이터를 캐시에 저장 → 해당 명령어를 CPU로 전송 → 완료

이처럼 캐시를 잘 활용한다면 비용을 많이 줄일 수 있음

따라서 CPU가 어떤 데이터를 원할지 어느정도 예측할 수 있어야 함

(캐시에 많이 활용되는 쓸모 있는 정보가 들어있어야 성능이 높아짐)

적중률을 극대화시키기 위해 사용되는 것이 바로 `지역성의 원리`

### **지역성**

> 기억 장치 내의 정보를 균일하게 액세스 하는 것이 아니라 한 순간에 특정부분을 집중적으로 참조하는 특성

지역성의 종류는 시간과 공간으로 나누어짐

**시간 지역성** : 최근에 참조된 주소의 내용은 곧 다음에도 참조되는 특성

**공간 지역성** : 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성

### **캐싱 라인**

빈번하게 사용되는 데이터들을 캐시에 저장했더라도, 내가 필요한 데이터를 캐시에서 찾을 때 모든 데이터를 순회하는 것은 시간 낭비다.

즉, 캐시에 목적 데이터가 저장되어있을 때 바로 접근하여 출력할 수 있어야 캐시 활용이 의미있어짐

따라서 캐시에 데이터를 저장할 시, 자료구조를 활용해 묶어서 저장하는데 이를 `캐싱 라인`이라고 부른다.

즉, 캐시에 저장하는 데이터에 데이터의 메모리 주소를 함께 저장하면서 빠르게 원하는 정보를 찾을 수 있음 (set이나 map 등을 활용)

<br>





--------------

#### references

sites : [github1](https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS), [github2](https://github.com/gyoogle/tech-interview-for-developer/tree/master/Computer%20Science/Operating%20System), [wv_github](https://github.com/WooVictory/Ready-For-Tech-Interview/tree/master/Operating%20System), [dh_github](https://github.com/devham76/tech-interview-study) [ws_github](https://github.com/WeareSoft/tech-interview), [trello](https://trello.com/b/BWtpfywH/%EC%8B%A0%EC%9E%85-%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B8%B0%EC%88%A0%EB%A9%B4%EC%A0%91), [goQ_github](https://github.com/Integerous/goQuality-dev-contents),  [Goodgid_blog](https://goodgid.github.io/category/#OS), [Dolphago_blog](https://m.blog.naver.com/PostList.nhn?blogId=adamdoha&categoryNo=81&listStyle=style1), [gyoo_blog](https://gyoogle.dev/blog/), [wh_blog](https://oolaf.tistory.com/m/123), [info for junior](https://github.com/jojoldu/junior-recruit-scheduler), [cheatsheets](https://github.com/rstacruz/cheatsheets)

books : [운영체제10th](http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9791185475578&orderClick=LEa&Kc=), [운영체제와 정보기술의 원리](http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9791158903589&orderClick=LEa&Kc=)

lectures : [kocw1](http://www.kocw.net/home/search/kemView.do?kemId=1046323), [kocw2](http://www.kocw.net/home/search/kemView.do?kemId=1349152&ar=relateCourse), [youtube1](https://youtu.be/zGBm37kze9I?list=PLHqxB9kMLLaOs2BM2KbuvttBYCgDoFm-5), [line_youtube](https://www.youtube.com/channel/UC4CjFOoZlYSaqMHEDFCKcXQ), [wooah_youtube](https://youtu.be/1xJU8HfBREY?list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH)

etc : 

- 스케줄링 목표 : https://jhnyang.tistory.com/29?category=815411
- 프로세스 전이도 그림 출처 : https://rebas.kr/852
- CPU 스케줄링 종류 및 정의 참고 : https://m.blog.naver.com/PostView.nhn?blogId=so_fragrant&logNo=80056608452&proxyReferer=https:%2F%2Fwww.google.com%2F
- 다단계큐 참고 : https://jhnyang.tistory.com/28
- 다단계 피드백 큐 참고 : https://jhnyang.tistory.com/156
- 파일 시스템 참고 : https://noep.github.io/2016/02/23/10th-filesystem/

- 이미지 : https://raw.githubusercontent.com/gyoogle/tech-interview-for-developer/master/resources/CPU%20%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81.PNG
- 이미지

--------------



